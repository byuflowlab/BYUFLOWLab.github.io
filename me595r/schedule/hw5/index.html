<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      HW &middot; ME 595R
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/my.css">
  <link rel="stylesheet" href="/public/css/academicons.css">
  <link rel="stylesheet" type="text/css" media="screen" href="/public/css/toc.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <!-- Icons -->
  <!-- <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png"> -->
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="/public/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="/public/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="/public/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="60x60" href="/public/apple-touch-icon-60x60.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="/public/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="76x76" href="/public/apple-touch-icon-76x76.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/public/apple-touch-icon-152x152.png" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- script -->
  <script type="text/javascript">  // used to hide/show BibTeX blocks
  <!--
      function toggle_visibility(id) {
         var e = document.getElementById(id);
         if(e.style.display == 'block')
            e.style.display = 'none';
         else
            e.style.display = 'block';
      }
  //-->
  </script>

  <!-- mathjax -->
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
  </script>


</head>


  <body class="theme-base-08 layout-top">

    <div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <h1>
        <a href="/me595r">
          ME 595R
        </a>
      </h1>
      <p class="lead">Deep Learning for Engineers</p>
    </div>

    <nav class="sidebar-nav">

      <a class="sidebar-nav-item" href="/me595r/syllabus">Syllabus</a>
      <a class="sidebar-nav-item" href="/me595r/schedule">Schedule</a>
      <a class="sidebar-nav-item" href="/me595r/resources">Resources</a>

    </nav>

    <p>&copy; 2025. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
    <!-- <h1 class="page-title">HW</h1> -->
      <h2 id="hw-5-neural-ode">HW 5: Neural ODE</h2>

<p>due 2/13/2025 before midnight via Learning Suite
<span style="float:right;">25 possible points</span></p>

<hr />

<p>We’re going to use a basic neural ODE to try to predict weather data by reproducing results from this <a href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">blog post</a>.  We’re using Python instead of Julia so don’t worry about reading the code, but the figures and some of the descriptions might be helpful.  <a href="https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data">This dataset</a> has historical data for temperature, humidity, wind speed, and pressure from Delhi, India over a period of a little over four years.  It is also separated into training and testing sets.  The training data is corresponds to about the first year and a half, and we’ll use that to make predictions for the remaining approximately two and a half years.</p>

<p>First, we need to do some data prep. The data provides daily information, but that is pretty noisy so we’re going to make predictions based on months.  So you’ll need to average the data within each month.  You can do that anyway you like, but the <a href="https://pandas.pydata.org">pandas package</a> is one handy way to do these kinds of data operations.  As usual, you’ll also want to normalize the data.</p>

<p>You’ll want to do incremental training, like shown in the blog, as opposed to trying to training across all the time-series at once.  This type of technique is used in many time-based problems.  If given all the time-series at once the optimizer will often settle towards a solution that just goes through the mean of the data to try to minimize error and will struggle to capture more complex dynamics.</p>

<p>As usual, you’ll need to experiment with the network parameters.  I find that the activation function can make a significant difference on this problem so you may need to venture into new activation functions (list of ones provided in PyTorch is <a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">here</a>).  While not necessary, you might find that you do better with different learning rates or number of epochs for the different stages of training (and by stages I mean stage 1 with the first 4 time points, stage 2 with the first 8 time points, etc.).</p>

<p>While you certainly don’t need to make animations like the blog post, you will want to plot at the end of each stage.  If things aren’t looking good after the first stage, they’re unlikely to improve with more stages, and you’ll want to see that without waiting for all the stages to complete so you can go back and change hyperparameters.</p>

    </div>

  </body>
</html>
